{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Education Review Sentiment\n",
    "\n",
    "Here's the first go at the sentiment model in both English and Albanian.  The configuration files with the hyperparameters are in the `./models` directory.  However, note that you can *override* these settings directly in this Juypter notebook (and this is done below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# environemnt configuration and set up: add this (deepnlp) library to the Python path and framework entry point\n",
    "from mngfac import JupyterManagerFactory\n",
    "fac = JupyterManagerFactory()\n",
    "mng = fac()\n",
    "# set facade defaults\n",
    "fd = {'lang': 'en', 'embedding_name': 'glove_50', 'model': 'wordvec'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful reporting functions\n",
    "def verify_configuration():\n",
    "    \"\"\"Verify the configuration for transformer model.\"\"\"\n",
    "    print('config:')\n",
    "    print(' ', facade.config['batch_stash']['decoded_attributes'])\n",
    "    facade.config['transformer_trainable_embedding'].write(1)\n",
    "    facade.config['transformer_trainable_resource'].write(1)\n",
    "\n",
    "def verify_dataset():\n",
    "    \"\"\"Verify the sentiment dataset splits.\"\"\"\n",
    "    print('dataset:')\n",
    "    facade.dataset_stash.write(1)\n",
    "    stash = facade.batch_stash\n",
    "    key_cont = stash.split_stash_container.split_container\n",
    "    key_cont.stratified_write = True\n",
    "    key_cont.write(1)\n",
    "    batch: Batch = next(iter(stash.values()))\n",
    "    point: LabeledFeatureDocumentDataPoint = batch.data_points[0]\n",
    "    print(f'  sample: {point.doc}')\n",
    "\n",
    "batch_clear_enabled: bool = True\n",
    "    \n",
    "def clear_batch():\n",
    "    \"\"\"Remove previous batches in case a new model is used for\n",
    "    which HuggingFace Tokenizer IDs differ.\n",
    "    \n",
    "    \"\"\"\n",
    "    if batch_clear_enabled:\n",
    "        from zensols.util.log import loglevel\n",
    "        with loglevel('zensols.persist.composite'):\n",
    "            facade.batch_stash.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm stratified splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facade = mng.create_facade(**fd)\n",
    "verify_configuration()\n",
    "verify_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English with Word Vectors\n",
    "\n",
    "We start with GloVE 50D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test\n",
    "mng.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add review features\n",
    "\n",
    "This adds the *emotion* and *topic* (course subject) as features to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facade.epochs = int(facade.epochs * 1.5)\n",
    "facade = mng.create_facade(**fd)\n",
    "facade.batch_stash.decoded_attributes.update('emotion topic'.split())\n",
    "mng.run()\n",
    "facade.persist_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fastText news embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd['embedding_name'] = 'fasttext_news_300'\n",
    "facade = mng.create_facade(**fd)\n",
    "facade.batch_stash.decoded_attributes.update(set('emotion topic'.split()))\n",
    "mng.run()\n",
    "facade.persist_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilingual BERT English\n",
    "\n",
    "Note that the hyperparameters were tuned for Albanian.  However, we still get decent results given we don't add *topic* or *emotion*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = {'lang': 'en', 'model': 'transformer'}\n",
    "facade = mng.create_facade(**fd)\n",
    "mng.run()\n",
    "facade.persist_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add back review features to the BERT model\n",
    "\n",
    "This adds the *emotion* and *topic* (course subject) as features to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facade = mng.create_facade(**fd)\n",
    "facade.batch_stash.decoded_attributes.update('emotion topic'.split())\n",
    "mng.run()\n",
    "facade.persist_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Albianian with Multilingual BERT\n",
    "\n",
    "Use the pretrained Multilingual BERT model.  First, verify the configuration and report the stratified dataset statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = {'lang': 'sq',\n",
    "      'model': 'transformer',\n",
    "      'transformer_trainable_resource_model_id': 'bert-base-multilingual-cased'}\n",
    "facade = mng.create_facade(**fd)\n",
    "# remove previous batches (see function doc)\n",
    "clear_batch()\n",
    "# make sure we're using Multilingual bert\n",
    "verify_configuration()\n",
    "# make sure we have the Albanian dataset\n",
    "verify_dataset()\n",
    "mng.run()\n",
    "facade.persist_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Albanian with Multilingual Roberta\n",
    "\n",
    "A multilingual model that's been trained with Albanian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = {'lang': 'sq',\n",
    "      'model': 'transformer',\n",
    "      'transformer_trainable_resource_model_id': 'xlm-roberta-base'}\n",
    "facade = mng.create_facade(**fd)\n",
    "# remove previous batches (see function doc)\n",
    "clear_batch()\n",
    "# make sure we're using Multilingual bert\n",
    "verify_configuration()\n",
    "# make sure we have the Albanian dataset\n",
    "verify_dataset()\n",
    "mng.run()\n",
    "facade.persist_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained Albanian model last epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now try the pretrained Albanian model (last epoch)\n",
    "fd = {'lang': 'sq',\n",
    "      'model': 'sq-transformer',\n",
    "      'mm_name': 'model',\n",
    "      'checkpoint': 'checkpoint-1855728'}\n",
    "facade = mng.create_facade(**fd)\n",
    "# remove previous batches (see function doc)\n",
    "clear_batch()\n",
    "# make sure we're using Multilingual bert\n",
    "verify_configuration()\n",
    "# make sure we have the Albanian dataset\n",
    "verify_dataset()\n",
    "mng.run()\n",
    "facade.persist_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try adding emotion and topic features\n",
    "\n",
    "This helped English more than it did Albanian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd['name'] = 'albanian add emotion topic'\n",
    "facade = mng.create_facade(**fd)\n",
    "facade.batch_stash.decoded_attributes.update(set('emotion topic'.split()))\n",
    "mng.run()\n",
    "facade.persist_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare results\n",
    "\n",
    "Generate a dataframe with the performance metrics of the previous runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zensols.deeplearn.result import ModelResultManager, ModelResultReporter\n",
    "rm: ModelResultManager = facade.result_manager\n",
    "reporter = ModelResultReporter(rm, include_validation=False)\n",
    "df = reporter.dataframe.drop(columns=['file'])\n",
    "df.to_csv('../sentiment-results.csv')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
